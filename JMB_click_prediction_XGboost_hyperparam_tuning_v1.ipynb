{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Click Prediction Project\n",
    "\n",
    "Matt Leffers, John Burt\n",
    "\n",
    "This notebook uses hyperparameter tuning to optimize XGBoost classifier based click predictor.\n",
    "\n",
    "Here, I use GridSearchCV to tune the classifier hyperparams. I also added a pipeline, which  will make it easier to add tuning of different data selection and transformation schemes in the future.  \n",
    "\n",
    "To install XGBoost:\n",
    "- conda install py-xgboost\n",
    "\n",
    "Some XGBoost references:\n",
    "- https://github.com/dmlc/xgboost\n",
    "\n",
    "- https://www.kaggle.com/phunter/xgboost-with-gridsearchcv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading original pickled data...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "pd.options.display.max_columns = 100\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.style.use('ggplot')\n",
    "# set all font sizes\n",
    "matplotlib.rcParams.update({'font.size': 18})\n",
    "\n",
    "# set all line widths\n",
    "matplotlib.rcParams.update({'lines.linewidth': 2})\n",
    "\n",
    "# set all symbol sizes\n",
    "matplotlib.rcParams.update({'lines.markersize': 10})\n",
    "\n",
    "matplotlib.rcParams.update({'axes.facecolor': 'white'})\n",
    "matplotlib.rcParams.update({'axes.edgecolor': 'black'})\n",
    "\n",
    "# nrows2read = 500000\n",
    "location='./data/'\n",
    "clickfilename = 'train'\n",
    "userdatafilename = 'train_users_only'\n",
    "\n",
    "converters = {\"site_id\": lambda x: int(x, 16),\n",
    "              \"site_domain\": lambda x: int(x, 16),\n",
    "              \"site_category\": lambda x: int(x, 16),\n",
    "              \"app_id\": lambda x: int(x, 16),\n",
    "              \"app_domain\": lambda x: int(x, 16),\n",
    "              \"app_category\": lambda x: int(x, 16),\n",
    "              \"device_id\": lambda x: int(x, 16),\n",
    "              \"device_model\": lambda x: int(x, 16),\n",
    "              \"device_type\": lambda x: int(x, 16),\n",
    "              \"device_ip\": lambda x: int(x, 16),\n",
    "             }\n",
    "#Import only the first nrows2read rows\n",
    "# data=pd.read_csv(location+'train.csv', nrows=nrows2read, converters=converters) \n",
    "\n",
    "clickcsvpath = location+clickfilename+'.csv'\n",
    "clickpicklepath = location+clickfilename+'.pkl'\n",
    "userdatapath = location+userdatafilename+'.pkl'\n",
    "\n",
    "try:\n",
    "    print('reading original pickled data...')\n",
    "    with open(clickpicklepath, 'rb') as handle:\n",
    "        data = pickle.load(handle)\n",
    "\n",
    "except:\n",
    "    print('error: reading original csv file')\n",
    "    #Import csv file\n",
    "    data=pd.read_csv(clickcsvpath, converters=converters) \n",
    "    # save data\n",
    "    with open(clickpicklepath, 'wb') as handle:\n",
    "        pickle.dump(data, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equalize number of click vs non-click samples for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original data = 40428967 rows: 6865066 clicks, 33563901 nonclicks 17.0% clicks\n",
      "training data = 4000000 rows, equal# clicks/nonclicks \n"
     ]
    }
   ],
   "source": [
    "# extract our X and y variables for training\n",
    "y = data['click'].copy()\n",
    "X = data[data.columns.values[2:]].copy()\n",
    "\n",
    "# from the larger dataset, subsample nsamps click and no-click records\n",
    "y0 = y[y==0]\n",
    "X0 = X[y==0]\n",
    "y1 = y[y==1]\n",
    "X1 = X[y==1]\n",
    "\n",
    "# nsamps = y1.shape[0] # use as many samples as possible\n",
    "nsamps = 2000000\n",
    "\n",
    "print(\"original data = %d rows: %d clicks, %d nonclicks %1.1f%% clicks\"%(\n",
    "    y.shape[0], y1.shape[0], y0.shape[0], 100*y1.shape[0]/y.shape[0]))\n",
    "\n",
    "y_eq = y1[:nsamps].append(y0[:nsamps], ignore_index=True)\n",
    "X_eq = X1[:nsamps].append(X0[:nsamps], ignore_index=True)\n",
    "\n",
    "print(\"training data = %d rows, equal# clicks/nonclicks \"%(y_eq.shape[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "original data = 500000 rows: 82037 clicks, 417963 nonclicks 16.4% clicks\n",
    "training data = 164074 rows, equal# clicks/nonclicks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  27 out of  27 | elapsed: 212.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 12951.565s\n",
      "\n",
      "Best score: 0.656\n",
      "Best parameters set:\n",
      "\tcolsample_bytree: 0.7\n",
      "\tlearning_rate: 0.2\n",
      "\tmax_depth: 7\n",
      "\tmin_child_weight: 11\n",
      "\tmissing: -999\n",
      "\tn_estimators: 100\n",
      "\tnthread: 4\n",
      "\tobjective: 'binary:logistic'\n",
      "\tsilent: 1\n",
      "\tsubsample: 0.8\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import xgboost as xgb\n",
    "\n",
    "# NOTE: the following comment was pasted from some example code:\n",
    "#brute force scan for all parameters, here are the tricks\n",
    "#usually max_depth is 6,7,8\n",
    "#learning rate is around 0.05, but small changes may make big diff\n",
    "#tuning min_child_weight subsample colsample_bytree can have \n",
    "#much fun of fighting against overfit \n",
    "#n_estimators is how many round of boosting\n",
    "#finally, ensemble xgboost with multiple seeds may reduce variance\n",
    "parameters = {\n",
    "            'nthread':[4], #when use hyperthread, xgboost may become slower\n",
    "            'objective':['binary:logistic'],\n",
    "            'learning_rate': [.2, .5, 1], #so called `eta` value\n",
    "            'max_depth': [7],\n",
    "            'min_child_weight': [11],\n",
    "            'silent': [1],\n",
    "            'subsample': [0.8],\n",
    "            'colsample_bytree': [0.7],\n",
    "            'n_estimators': [100,500,1000], #number of trees, change it to 1000 for better results\n",
    "            'missing':[-999],\n",
    "            }\n",
    "\n",
    "xgb_model = xgb.XGBClassifier()\n",
    "\n",
    "# Create the grid search object.\n",
    "# Note that \"n_jobs=-1\" means that the search will use all of the \n",
    "#  computer's available processing cores to speed things up.\n",
    "grid_search = GridSearchCV(xgb_model, parameters, n_jobs=-1, verbose=1)\n",
    "\n",
    "print(\"Performing grid search...\")\n",
    "# print(\"parameters:\")\n",
    "# print(parameters)\n",
    "t0 = time()\n",
    "\n",
    "# Run the grid search to find the best parameters for the classifier.\n",
    "grid_search.fit(X_eq, y_eq)\n",
    "\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print()\n",
    "\n",
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
